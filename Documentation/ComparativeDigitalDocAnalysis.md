Comparative Digital Document Analysis
-------------------

A:Craig Duncan

D:12 September 2024

# Licence

See [Licence](LICENCE.md)

# An introduction to Comparative Digital Document Analysis

Comparative Digital Document Analysis is based, in part, on an analytical framework for digital documents that gives priority to the function of digital information (whether it be data, encoding, files etc) that remains within the computing system, in the context of general computing.  It focusses on the process of encoding information in digital form right up to the point it is converted to analogue signals in a standard output device, like a monitor or speaker.  

One initial method of analysis is to view the digital documents as part of a linear sequence of inputs and outputs, bridged by some model of a computer represented by specific software.  Using that analysis, we look for the point at which digital computation ceases, and analogue representations for human beings commence (this is not the end point of thinking, but it may be the end point of computation, in that model).  The layperson may be unaware of this lack of continuity, and will *recognise* or project the on-screen representations of documents in such a way that it is indistinguishable from any unseen, preceding digital form that produced it.  

Sometimes this blurring of the digital/analogue boundary can be broken or rewound.  A browser, for example, can choose to make HTML code, otherwise a <i>preceding</i> step in this model, available as if it were a final analogue output.  This is done by 'view source'.  

# The usefulness of a model of computation up to the point of analogue representation

The notion of rewinding digitally-produced analogue representations back to the last preceding digital representations is intimately bound with the need for humans to be offered another analogue representation, in each case, to make sense of that process.

How far back we decide to rewind the process of computation is arbitrary.  We do not need to roll back to the preceding digital forms, if we can imagine multiple intermediate stages in the process of computation.  For example, a computer programmer usually wants access to visible text in the form of 'code' because it is considered convenient for manual viewing and updating low-level instructions for the computer.  You can even write code to produce HTML, so the code that does this might be regarded as 'preceding' the HTML source, which in turn, precedes the analogue representation of that code in a browser, in a form that a human can read.

Using our linear model of digital computing, however, we would describe the digital documents that a programmer works with in terms of the digital and analogue forms of information that are provided in the context of a much longer process of computation that will ultimately not involve the programmer at all.   The programmer temporarily accesses some digital documents in an analogue form, but later, those documents are seemingly invisible in the process of computation as a whole.   

# A concept of input-output time for analysing digital/analogue forms of documents

How do we explain the difference between the text in these programmer documents and the text that may be in the ultimate analogue output of a program?  In the context of a model of the complete computing process, interrupting the input-output process to perform programming is a kind of 'rewind' (if we describe this relevant to where the final analogue output occurs).  Each time there is this kind of deliberate interruption, it is also combined with some interim, 'functional analogue output', i.e. a decision to produce a text-based analogue output of the code, for the purpose of allowing the programmer to work on the digital document that is thereby created.  

This example suggests that digital documents can be produced at any 'time', with reference to a concept of 'input-output' time.  We can choose almost any intermediate point in the computing process to artifically create a point of human interaction with the computer. For most of the history of computing, this has largely been considered what comptuer programmers do, but there is no reason why we can't extend this idea to anyone who writes using a computer.  We can deliberately create new opportunities to interrrupt and expand the opportunities for any writer of digital documents to interact with the computer before some arbitrary end point where the digital computation ceases, and is replaced by a terminating analogue representation of the document. 

In general, it is possible to interrupt a process of computation to :
- create a digital document in the sense that it captures something that might be of importance to humans using the computer; and
- prepare an analogue form (or different analogue forms) by creating different programs for interpretation.

# The consequences of deliberateness in preparing digital documents

Knowing that we can create intermediate points between writing and analogue output, we can consider these things:

- some notion of quality control, 
- analysis of the efficiency of encoding the writer's message as encoded digitally, and 'noise';
- the extent to which interim semantic or computable information is progressively retained and captured in the penultimate computational form.  

Having a clear sense of where digital computation ends, and where in the input-output timeline the digital format is actually visible, helps us focus our programming efforts by pinpointing where we should be seeing the consequences of preceding digital computing. The HTML source code, for example, is a penultimate form of digital information that can be configured by preceding text editing process and deliberate methods for retaining semantic information.

# Subtle reframings of time and sequence in graphical editing software

What I have just discussed is a linear, sequential model of computing that focusses on input-output as a way of modelling digital computing events.  This is convenient and useful for the analysis of the process of creating digital documents.  It is also useful for understanding the way in which graphical text editing software uses a different model for what the human user sees.

A graphical software program for text editing might not give the user any sense of this input-output computing time.  The analogue interface that represents the image of a document only models the user interface as an ever-refreshing 'present'.  To the extent there are events that can be used to give a sense of time, we can observe that from what is recorded in 'undo' or 'redo' buttons.  These are events that exist in the 'analogue representation time', rather than any lower-level computing model that takes digital input and, by events in some 'computational time', moves steadily from digital to the final analogue output.

When we think about the idea of 'rewinding' from the perspective of computational time, we think of everything prior to the analogue representation. For example, by looking for some preceding computational step immediately before pixels are updated in a graphical text editor or web browser, we might be drawn to look at some recognised form of data format that is independent of the pixels on screen.  One way of getting access to something like this is to look at the file format stored on the disk, and inspect the more explicit digital formats like OOXML.  

As it turns out, examining OOXML file format is a fairly analogous process to inspecting HTML source code in a browser.  In both cases, what we are doing is looking for the place where digital computing might end, and analogue representation begins. 

Looking at digital file formats through the lens of 'computing time' rather than analogue representation time is one way we can start to unpack what kinds of pre-graphical information we might want to include in an HTML file that is being imported into a program that will use something like an OOXML format.

# E-readers

In the case of digital documents that only have the expectation of producing analogue output for human consumption, there is no real expectation of rewinding, in computational time, to the digital/analogue boundary (i.e. they don't offer the ability to view HTML source, for example).  A mobile phone with a broswer application is also likely to be indifferent to offering HTML source inspections.

# Comparative digital analysis is based on a general computing model for information

Comparative digital analysis is based on paying attention to sequential computing processes, and being aware of the digital/analogue discontinuity in computing.  It is not based on an economic model referring mainly to analogue outputs in commercial software production.

Comparative digital analysis uses the idea of computational event analysis to compare and contrast digital formats, rather than analogue representational events.  We can consider multiple ways in which a digital document becomes relevant to the computer, in any process prior to analogue representations.  This might include it being repurposed as a kind of program, even one that will operate on itself.

All of what I said at the beginning about how a human being might be invited to visually inspect earlier parts of the computing process still apply: to the extent we can imagine a digital document within the computing process is capable of containing instructions, or programs too, we can then offer an analogue version so that a human can not only see, but interact with that earlier stage of the computing model.   In my view, this is what allows us to think about reframing and interpreting digital text documents as both documents intended for analogue representation, as well as something that can be considered a program, even one that operates on itself.

Once we have a broader awareness of what is possible, we can better perceive the limited choices or missed opportunities associated with the form of digital documents that only work backwards from analogue output to determine the form of the intermediate, computable forms.  This paves the way for comparative digital document analysis that is conducted within a framework of comparing the structure and function of digital documents throughout their entire history of preparation and use, and not merely by the output.

# What parameters are important in this analysis?

Our analysis of any digital document format can include these questions:

- whether a format like HTML is information-rich or noisy from the perspective of the writer's original semantic data and literary goals.  
- whether any standards for how information and data is packed into HTML will make it easier to retrieve that data in downstream processes.
- whether the information is packed into HTML as a response to the desired analogue output, or independently of it.
- whether the information in the HTML, in terms of data structures prior to its final, published analogue interpretation, is capable of independent interpretation by a computing machine, or whether its importance is only evident in the analogue representation perceived by a human being.

If information other than the writer's own semantic content is incorporated into the document merely through the publication process, then the end result is often a noisy document and inconvenient structures for re-acquiring the information down stream.  However, informed data standards for HTML preparation may make that task easier.  For example, implementing MessengerHTML should make it easier to scrape data from the HTML with something like Beautiful Soup, than HTML prepared in ignorance of downstream uses.  
With Messenger HTML, if you turn off CSS you will still have something that contains the same data in its HTML, and is probably very clean and simple in your browser as well.  Your code should, in its HTML form, be clean and readable without too many nested tags or distractions.

# Writing syntaxes designed for analogue-focussed digital output

Even though writing in a digital computer may seem like 'digital' input, if the main focus of the software output is analogue presentation (to a human reader), and it lacks attention to data, then it is likely that it remains analogue-focussed digital software from input to output.  This analytical description helps us become more aware of the fact that the computable functions in software that interprets or transforms using this as the principal syntax will tend not to offer the writer any intermediate computing functions that do not relate to analogue output.

For example, Markdown syntax (John Gruber) is capable of being analysed as a shorthand version of HTML, in that its primary focus is to help the writer provide instructions for analogue layout, but disguising that function by making the text look like it is a set of detective's notes written in an old mechanical typewriter.  This has little interest in making it easier to record the text for data transmission purposes.  However, it has created or perpetuated the culture of focussing on analogue representations as if they defined what a digital document is.  This now extends to analogue-representation converters like pandoc.  The reason that YAML formats are supplementary data sections within Markdown and pandoc Markdown is largely because the analogue-focussed digital format is supplemented with data only where it is deemed necessary, but not because data is a first-level concern of the computing process.

# Informed upstream processing

By adopting a functional definition for digital documents that includes some use of writer's data, we can move toward more deliberate processes that aim to achieve retention of semantic information.  This can help with a new kind of definition for what we mean by digital media and a semantic web.

We have a choice, for example, between digital texts that merely use text decorations for standard output, like Markdown, or ones that build-in the expectation of general functions and data definition blocks within a literary of essay-like text.  This allows the writer to work with a program that does not allow analogue representation to dominate the possibility of data and computable text.  This isn't just a change to how we produce analogue output; it is also a change to the extent to which a writer can use computation and numerical tools, or text processing, within the same software that is allowing them to process text.

I am not merely describing an integrated text editor that has extra features.  My initial project is based on the idea that we can prepare a digital document in any text editor and that what matters is having a program that provides an interpretation of its contents.  To the extent this allows data storage and functions, I call this a programming language, and an interpreter, rather than a 'markup language'.  Of course, it has features in common with both markup languages and programming languages, but these are fundamental to computing: data partitions, grouping of text.  These are true of any data format; what matters is what we enable the computer to do with it.

Another interesting possibility of this analysis is that rule-based processing of documents, as a text stream (rather than using a document object model) can be enabled by allowing the writer to use functions that apply to the balance of the digital document (assuming a top to bottom processing direction).  Any programmatic interpretation of digital text files offers the possibility that line by line marking up can be replaced by an automated pattern-matching and replacement process.  For example, we can deliberate program the text interpreter to act on replacement rules that look for particular text, and if it is found, process it to standard output with a particular category.  This auotomatic semantic labelling is very effective for auto-formatting of plays in literature, for example.

Another observation is that even a basic text editor provides some analogue representation, because this is how a human reads it.  However, in programming or coding, it was always understood that this was merely a means to an end, namely the subsequent processing of the crafted text file as instructions for a computer.  From this we should conclude that any digital file can exist simultaneously as both an analogue representation and one that is capable for computation.  

By taking this observation and thinking about how it might apply to the whole process of computing, from input to output, we can ensure that the notion of analogue representation does not become a limitation on how we interpret and process digital texts for any purpose, not merely for software engineering.  For example, in my project, a text file does not fall neatly into the category of a memo or program, or an essay or program.   It is possible to have functions and data blocks in the same 'file' as a play, as well as having two files where the more functional elements are separated.  The point is, that it is not the fact that we can see the document on the screen that is important: what is important is how much the computer environment is prepared to process the file for different functions, and how much the human writer is prepared to take advantage of that deliberate computing model. 