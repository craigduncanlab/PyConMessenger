T:Preprocessing Markup
A:Craig Duncan
D:7 August 2024
C:These are alternative ways of describing MemoScript
B:ScienceWritingNotation
F:DigitalDocuments

# Intro

My work flow to try to introduce 'semantics' into the publication of materials on the internet has explored the idea that we can introduce layout into a much reduced set of tags, freeing outselves of the need to be stuck with the language of HTML.  This is merely a doorway into a larger topic, namely can the semantic categories (or any author-chosen category) be successfully introduced into the earlier stages of the workflow?

At first, the link between markup and HTML is merely facilitative: markup is designed to free writers of repetitive tagging (of the semantic layout scheme for HTML).  'Markdown' involves a kind of symbolic brevity and abstraction, yet it doesn't have its own dependencies.

On the other hand, notebooks can have code and writing in them (and part of this is using markdown).

# Understanding digital media

The kind of analysis that Scott McCloud undertook for comics is lacking for an assessment of digital media, including word processing, and the web and so on.  Even the idea of 'format converters' is an under-developed idea because it presumes we know something of the languages that are being converted, or interpreted.   If those languages are themselves based on preconceptions that relate to old media types, then we aren't really travelling much further toward understanding existing or potential digital media.  Also, all the new software programmers, or scripters, that are busy trying to develop web pages that have television or movie-style transitions and effects are really applying their knowledge to the 'information as entertainment' industry, rather than being artists, or assisting artists, who want to explore the realm of the internet (more specifically, easily-accessed, networked digital media) for its other possibilities.

Those who understand comics as an integration of words and pictures might realise that there is more to a media than just trying to imitate another (see /ImitationAndMediaTheory/).  However, in the case of comics, two different language systems are operating together.  In the case of digital media, there are many more possible routes toward what we mean by texts, literature and art.  There may be genres that we haven't given names to.  For example, I think that the 'scientific notebook' (R markdown, Jupiter notebooks) is a kind of genre.  However, it is different to most comics in that it clearly separates the writing and the science-computing (code or plots).

I'm interested in new genres (which have to be created from scratch, since they are not really understood at yet).  For example, the multitude of different digital formats for Shakespeare's plays are really just alternative systems for making books (i.e. imitating paper media).  Whether this is PDF, eBooks, HTML pages etc, the reader software generally uses some digital language that helps package the raw text (as if it were written on a typewriter, on paper, with lines, and type) for page-by-page navigation in a digital medium.  The 'format' that both facilitates this and also makes it foreign to a different text reader is really concerned with the intelligibility or unintelligibility of layout formats.  Whether something is 'understood' by a reader depends on whether that reader can speak the language by which the text was encoded for its book form.

The genre of digital books has its own history.  Some of this is related to ideas of navigating, numbering and turning pages (it even extends to hardware like Kindles and hardware designed for holding digital books).  However, it's also seen as an industry for digital readers, where the main audience are the consumers of digital books.  Those who are trained to program are turned into agents for the producers of such books.

The genre of content mangaement systems and 'litigation management systems' is also based on applying an engineering-style approach to digital versions of documents based on imiation of traditional media.

There is another possible role for programmer-writers, and that is in the self-production of digital art that does not have to conform to the expectations of digital readers (which are themselves imitating old forms of media).   Such artists might be trailblazing a new path in which due to their ability to prioritise the simultaneous consideration of programming, content and presentation (or even navigation and linking), they can create tools which allow them to produce works of digital media that are not so easily classifiable according to traditional genres.   They aren't working by moving between image editors and word processors, and thus perpetuating the consumer-based framing of what a computer does and how.

Even social media is a genre in that it represents an open telephone-conversation between participants (using transcript rather than voice).   Communicating in this field (with images juxtaposed with text, and also with the ability to juxtapose a response to an earlier reply) is another case of paired words and images, but without necessarily allow author control over the page, or the programming of a page.  The facilitating software (ActivityPub in the case of Mastodon etc) is largely built on a database and server model (the 'blood' of the system is the writing, and the veins are the servers and computers upon which the text/images are disbursed).

# Preprocessing markup

With this background, what is the point of preprocessing even something like markup/markdown?

By preprocessing I mean substituting it with something that has more programmable elements: so that what would be a code-block in something like R markdown becomes a data block that can be treated as general data for re-use.  Importantly, such data would be directly referable to the author's intentions at that intermediate stage, and allow for choice.  It can be converted into text, or kept as raw text.  It can be processed into discrete columns/vectors of data and used for a table.  In addition, it can be data that is then used to help auto-tag layout and other presentation elements, so that the writer is no longer a passive consumer of this publishing format/environment called 'HTML' or similar, but someone who can actively use a computer to direct that patterns of information are going to appear in a particular way.

As an extension of this, the preprocessing step is one that can prioritise the author's own language and semiotic systems, or semantic systems.  The writer can introduce a kind of personal intelligence into the writing which subsists in their original form of writing.  They do not need to submit and lose this form of writing to whatever external language system governs the workings of browers, the internet or some protable document format.

This genre involves personalised data variables, or an intention to develop something we might call 'iconic memory' - digital representations of things that we want to recall and use.  Some in computer science call approaches that employ conceptual data structures 'object orientated', but I don't want to be so prescriptive, or tie this idea to all the other specifications of what that means.  

Without being concerned with specific programming implementations, or memory use, what I mean by 'iconic memory' is the ability to describe digital text with labels that can be re-used as part of interpretable instructions in a computer.  Normally, this only occurs in the context of a computer 'program', which traditionally has been a genre, or form of digital text (literature) that is only going to be used by a computer.  This is distinguished from another genre, namely a passive data format which requires interpretation because it does not follow a systematic language that can be intrepreted as computer-based instructions.

The reason new terms and language are needed here is because those traditional distinctions between computer programs and data are mostly convention, and they also help separate concerns when people are interested in doing so.   However, they also work on other deeper divisions, like the assumption that traditional media and literature was neither a system of either passive data encoding or a set of instructions that could be interpreted (logically) by a human being.  In truth, it could be considered either, or both.  

What matters more is the system of interpretation than whether it is in electronic or digital form.  The fact that something very similar to traditional media still appears in digital form (i.e a 'text file' rather than a binary file) is based on the necessity and utility of converting data into character blocks, and then converting those streams of characters into a form that works on a screen.  The simplest text editor relies on delimiters like line breaks or wrapping of text inside a finite window to allow a person to read it.  

This fundamental, low-level organisation of text means that 'plain text' is one of the most universal digital genres there is.  There are basic tools for seeing and working with text that will be displayed as characters on the screen.  Yet even these are not equivalent to the display of text and images on a screen.  Either the simple idea of 'characters' has to be broken up with internal blocks of data that can be converted to pixels, or the text file needs to be interrupted with instruction blocks that direct the interpretation program to insert an image when it gets to that part of the interpretation of instructions.

It's the higher-level of organisation, building on the genre of plain text, that allows further abstraction and encoding of things like layout to be added to what is otherwise a plain text file.  The internet assumes that HTML, a basic genre in which tags are used to indicate how what is otherwise plain text (utf 8 or utf 16 etc) can be supplemented by styles, or can be arranged into tables, or can have images inserted.  These are the basic assumptions.  As time has gone on, further additions for video format inserts, or colour, or transitions have been added in the form of scripting languages that process data blocks into images and gradients.  The concept of a 'canvas' has been introduced to allow finer control over inserted internal images.

The concern for what the technology can do has overshadowed any general interest in how we might analyse traditional forms of media to understand what elements are being combined, or used, so that these provide some input into the languages that exist in computing, for different kinds of digital artistry.   The focus in computer science is on providing industrial solutions to general problems, as if what will be offered to consumers will be a range of standard options, and people will be trained up, as the need arises, in using standard systems to offer new results.  As a result, the infrastructure of the web is developed, layer upon layer, upon the assumption that the end user is a consumer, and that the infrastructure is made by producers.  

What is not considered is : in what way are traditional genres recognised and catered for in languages that allow authors more specific control over the presentation of that information, in a language that reflects their own?  How can genres of literature be accomodated by languages that can be used within and in relation to ordinary writing, rather than first requiring a software monolith that tries to service these artists by a dispensing-machine model?  The dispensing machine thinks in terms of menus, and options, and functions (everything is done as if language and author point of view is absent: the software is always the 'other' to the consumer/user).   What tends to happen is that software that is attempting to assist an artist immediately over-mediates between the artist and their subject.  It doesn't conform to the artist so much as make the artist conform to it.

In some cases, the software has always been so out of touch with the author viewpoint that it is considered normal to do it this way.   Making web pages whilst simultaneously writing in mostly plain text has not been considered normal (even notebook genres still require infrastructure and set up and some programs that are very large to do it).   In conjunction with this, expectations about old media (like making books) dominates the way in which software is written to service the artists.  There's an ongoing lack of awareness that the simulation of old media should be permitted, but not enforced, upon artistic endeavours.

Web comics has been inserted within content management systems that are themselves database-driven libraries for small version of traditional media (e.g. the 'post').  They don't allow the author ease of manipulating the parts of their art in ways that represent any kind of 'iconic memory'.   What if an author wanted to label an image and re-use it here and there, or easily create a customised look without being required to go down the road of custom themes and templates?   

# Digital genres as inclusive of traditional genres

The assumption of software makers is that the way to make life 'easier' for any non-computer person is a choice between 'configuration or conformity'.  This is based on the consumer-producer model of software.  However, if you think of computing in terms of creating languages for authors, then there are many possible languages that can be written to enable digital authoring to embrace both new ideas and create new genres: with new languages it might even be possible to see traditional genres as merely subsets of a wider range of digital genres.

For example, if you have the ability to detect the references to characters in a play or transcript, then the ability to create iconic memory for these, then instruct the program to link these to particular styles, means that you can link traditional genre of play with the newer media of transcripts of interviews (or court proceedings) or podcasts.  The way of setting these out with references to the speaker is the form of the traditional genre, but in a digital medium there is no reason why that semantic information cannot (or should not) be included in the information the programs can work with.   

# Why preprocessing

The point of preprocessing is to take traditional representations that now appear in digital media in the plain text genre, and:
l+
automatically convert these to more semantically-orientated encodings without the author having to do this; and/or
customise these according to the author's own wishes, using a simple programming language fit for purpose.
l-

If the software programmers are more attuned to the elements of traditional media they will not only provide superficial simulations of what those non-digital media look like, but will assume that authors want to do work to take advantage of the ability to refer to parts of these texts or literary genres in an intelligent way.  

In order to do this, it is necessary create an intermediate, digital concept of what is included in a literary work, and provide more high-level computer languages that work with that.  By creating more tools to engage with this plain text genre, it opens up the entire workflow to greater author input and sophistication of digital representations, where the author has control over the additional inclusions, and how they are referred to, within a digital text.   

The digital labelling of text, and the labelling of author intentions for a digital text, are some of the omissions in the current digital workflows and software.   The digital medium needs space and time for author's to reflect on what it is capable of, without being told what it can or cannot do by the producers of the current software (mainly non-digital-genre-simulating software, or database-inspired dispensing machines).

With a broader vision for how authors should use digital texts, a digital text becomes a combination of text, images, instructions, data manipulation all interacting seamlessly.  In turn, authors will feel free-er to include more digital connections (e.g. navigation, or captions on texts, or notes and asides) within digital output that would seem to advanced for most content management systems, but will appear easy for authors to specify, because they know their medium and audience better than the software developers.

I know that Brett Victor has talked about working with code in different ways, and offering interfaces to help describe, for example, a fish 'swimming' in a way that a coder can obtain feedback on what quantitative changes are needed to achieve qualitative ideas.  He's talking about a different interface, or a different language, to wrap around traditional coding.  I'm talking about a different way to interact with the digital medium in general, inclusive of text.  I'm trying to pause at that moment between transferring a plain text version of Shakespeare to a computer, and the options that teacher, student, playwright or actor might want in relation to working with that text.  The general desire to label, annotate and work mroe abstractly with texts is not going to be catered for until we develop abstract languages and relations between humanities and the computer that don't draw a hard line between the idea of coding and writing.  

# What kind of mix of writing and code might be characteristic of a digital text?

By code, I do not mean full-blown general purpose coding languages with branching and loops either; for some purposes just simple functions and data definitions might be enough to add a lot of interest and value to digital texts.  Using these methods, we do not have to think of a text as merely a data format either.  A plain text document has already inherited structure from traditional media (just to present it visually, as text, requires giving some priority to how the human visual system works).  

We might also consider that a digital text is not just one electronic file (even in Word processing, this is not the case: docx is a package format that hides several OOXML files).

A digital text could be something that pairs a plain-text-digital genre file with a supplementary semantic file, containing things useful for iconic memory.  Further processing (but 'pre-processing' from the point of view of markup or HTML) can include adding useful information to these texts so that more intelligent computing can take place without needing any immediate changes to that data format.  A digital text might be conceptualised as a combination of some semantic data, some author instructions, and a digital plain-text-genre version of a non-digital text.

# Some interim conclusions

The idea of 'preprocessing' assumes we are interested in a sequential workflow; the input-output metaphor is a powerful one in computing and tends to dominate these descriptions.  However, by changing the language to genres, we can start to think about what is offered by a particular digital file format, and the possibility that the relationship between a text and its author can be radically reinvented with new languages, coding schemes, and software to assist the author to transform intention into goals.  Those goals need not be immediate publication: they might even be self-serving intermediate formats, perhaps even wanting HTML to be an intermediate format to transfer information to a word processor without having to work within the confines of the word processor.  Word processors only seem to offer advantages when the availability of other, more author-friendly software is so poor.

# Intermediate digital formats requires letting go of the short input-output metaphor.

When we let go of the input-output metaphor that requires we go directly to 'standard output (e.g. printing)', we might find that genres like 'teacher-texts' or 'digital legal texts' acquire their own meanings and modes of operating.  We won't think of adapting word processors to these genres; rather we'll think about what concepts and options the writers want, and make languages that seem more natural to these practitioners.  Why shouldn't a lawyer be able to define, in a semantic file, lists of data like elements of a cause of action, and then link these to the headings/blocks of text in the main document that refer to these?  Why shouldn't the next round of pleadings not be able to refer to the 'iconic memory' that relates to the specific text that contains the information they want to respond to?  Ideas like sequence and flow in digital documents are not that different from the idea of motion in comics: practitioners bring their own ideas of motion and closure (cf Scott McLoud's Understanding Comics, page 107), but that doesn't mean they can't define the 'panels' they want to regard as being connected.   

For example, a litigation or court lawyer may want to create or be the author of a sequence of text blocks, when they assemble the various parts of legal pleadings/documents together.  They do this to more easily consider the logic of them.  A person discussing the sequence of relevant parts of a legal contract or statute might want to refer to those parts and reproduce them within their texts or submissions as easily as if they were inserting an image.  Their writing contributes to reproducible reasoning in that their original form of text can insert references to digital documents that are easily understood within a system of writing that keeps track of documents in ways that are also easily comprehended by human beings (and not hidden away in complex databases, or made difficult by assumptions that authors only ever work on one document at a time).

Another example is if a person writes each document as if it were a memo, then it's date and author are easily processed by computer.  In some cases, would we prefer to write digital documents in a slightly different way if it gives us the ability to (a) use a computer to find and use information based on its type (e.g. dates, titles etc) (b) if necessary, convert the output to old-style media if we want to?   So many people are still writing letters in digital media as if there were no advantages to changing media/genres.  It's the lack of a 'preprocessing' mindset that obscures the advantages.   Should we be writing everything as if it is immediately going out the door?  No.  We can pause, reflect, compute and do other things whilst still preserving the ability to transfer back to traditional media. Unfortunately, the software industry wants people's perceptions of those intermediate possibilities to be as narrow as possible.

In a digital medium, if an author can use labels to refer to the parts of other digital documents, easily, then they can engage in pseudo-programming (or actual scripting), to do things in digital media that are simply not possible in old meda.  This includes taking parts of digital documents, extracting them or outputting them to a new, filtered document.  All of the handling/rehandling of digital genre text that goes on presently is an unfortunate side-effect of word processing trying to emulate old media (and thus missing out on the possibility of new digital genres).

# Recycling

Let's say that someone like Rosemary Huisman conducts a computer-assisted study of lexcial patterns in Beowulf (as she did in her PhD), or Alison Whittaker conducts a computer-assisted study of word frequency in coronial enquiry reports or legal judgments.  These insights can be used analytically or creatively.   Yet in both cases we could regard them as providing semantic data, or iconic memory, in a digital medium.  Once this text has been identified, then the process of !!auto-tagging!! (see /AutoTagScripts/) could take this and introduce some custom formatting or high-lighting to draw attention to this in its original context (i.e. no longer is it passive, or implicit in the original form: it becomes explicit).  The relationship between reader and text can be changed, deliberatively, by introducing different semantic schemes.  Similar mechanisms are at work in comics where different fonts are used in a pattern, or different sized text is used for a regular emphasis.  (See for example Padua's use of gothic script for Queen Victoria at p73-p85 of L&B, including when she break's the 'fourth' wall on p84).